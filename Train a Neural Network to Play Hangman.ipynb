{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Neural Network to Play Hangman\n",
    "\n",
    "by Mary Wahl, Shaheen Gauher, Fidan Boylu Uz, Katherine Zhao\n",
    "\n",
    "In the classic children's game of Hangman, a player's objective is to identify a hidden word of which only the number of letters is originally revealed. In each round, the player guesses a letter of the alphabet: if it's present in the word, all instances are revealed; otherwise one of the hangman's body parts is drawn in on a gibbet. The game ends in a win if the word is entirely revealed by correct guesses, and ends in loss if the hangman's body is completely revealed instead. To assist the player, a visible record of all guessed letters is typically maintained.\n",
    "\n",
    "The goal of this project was to use reinforcement learning to train a neural network to play Hangman by appropriately guessing letters in a partially or fully obscured word. The network receives as input a representation of the word (total number of characters, the identity of any revealed letters) as well as a list of which letters have been guessed so far. It returns a guess for the letter that should be picked next. This notebook shows our method for training the network and validating its performance on a withheld test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "\n",
    "- [Set up the execution environment](#setup)\n",
    "- [Extract a list of unique words from the input data](#input)\n",
    "- [Partition the words into training and validation sets](#split)\n",
    "- [Create the game player](#player)\n",
    "- [Create the model](#model)\n",
    "- [Train the model](#train)\n",
    "- [Evaluating results](#eval)\n",
    "- [Just for fun -- play hangman with your favorite word](#fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"setup\"></a>\n",
    "## Set up the execution environment\n",
    "\n",
    "There are two readily available options on Azure to run this notebook if you should choose to do so.\n",
    "\n",
    "1) Create a GPU VM with CNTK 2.0 RC2 pre-installed using the [Azure Deep Learning toolkit for the DSVM](https://azuremarketplace.microsoft.com/en-us/marketplace/apps/microsoft-ads.dsvm-deep-learning) and set up the VM's Jupyter Notebook server using the [provided instructions](https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-data-science-provision-vm#how-to-create-a-strong-password-for-jupyter-and-start-the-notebook-server).\n",
    "\n",
    "2) Provision a [Microsoft Azure Data Science Virtual Machine (DSVM)](https://blogs.technet.microsoft.com/machinelearning/2017/06/06/introducing-the-new-data-science-virtual-machine-on-windows-server-2016/) with Windows Server 2016. They come  pre-installed with the GPU Nvidia drivers, CUDA toolkit 8.0, and cuDNN library.\n",
    "\n",
    "We then loaded this notebook on the VM before executing the code cells below. VM images are updated regularly, but at the time of this writing, the following package versions were pre-installed in the `py35` Anaconda environment on the VMs respectively:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebook was tested with   \n",
    "Python version: 3.5.2 and 3.5.3  \n",
    "Anaconda 4.4.0 (64-bit)  \n",
    "CNTK version: 2.0rc2 and 2.0  \n",
    "NumPy version: 1.11.2 and 1.13.0  \n",
    "Pandas version: 0.19.1 and 0.20.0  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, cntk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print('''\n",
    "Python version: {}\n",
    "CNTK version: {}\n",
    "NumPy version: {}\n",
    "Pandas version: {}\n",
    "'''.format(sys.version, cntk.__version__, np.__version__, pd.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your output is different when you run the code cells above, version differences may impact this notebook's function. You can use the following command to install a specific package version if necessary:\n",
    "\n",
    "`pip install <package-name>==<version-number> --force-reinstall`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"input\"></a>\n",
    "## Extract a list of unique words from the input data\n",
    "\n",
    "We train and validate our model using words from Princeton University's [WordNet](http://wordnet.princeton.edu) database. Specifically, we download the [tarballed version of WordNet 3.0](http://wordnetcode.princeton.edu/3.0/WordNet-3.0.tar.gz) and use all words (consisting only of alphabetic characters) from the following files from the tarball's `dict` subfolder (which we transfer to a local folder named `input_data`):\n",
    "- `data.adj`\n",
    "- `data.adv`\n",
    "- `data.verb`\n",
    "- `data.noun`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We augment this word set with a few phrases, like \"Microsoft\" and \"CNTK\". We then randomly partition the words 80:20 to create training and validation sets of 44,503 and 11,226 words, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = {}\n",
    "input_files = ['./input_data/data.adj',\n",
    "               './input_data/data.adv',\n",
    "               './input_data/data.noun',\n",
    "               './input_data/data.verb']\n",
    "\n",
    "for filename in input_files:\n",
    "    with open(filename, 'r') as f:\n",
    "        # skip the header lines\n",
    "        for i in range(29):\n",
    "            f.readline()\n",
    "\n",
    "        for line in f:\n",
    "            word = line.split(' ')[4]\n",
    "            if word.isalpha():\n",
    "                word_dict[word.lower()] = None\n",
    "\n",
    "word_dict['microsoft'] = None\n",
    "word_dict['cntk'] = None\n",
    "\n",
    "# create a list to be used as input later\n",
    "words = list(np.random.permutation(list(word_dict.keys())))\n",
    "with open('word_list.txt', 'w') as f:\n",
    "    for word in words:\n",
    "        f.write('{}\\n'.format(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"split\"></a>\n",
    "## Partition the words into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 44460 WordNet words\n",
      "Max word length: 31, average word length: 8.6\n"
     ]
    }
   ],
   "source": [
    "# During training, the model will only see words below this index.\n",
    "# The remainder of the words can be used as a validation set.\n",
    "train_val_split_idx = int(len(list(word_dict.keys())) * 0.8)\n",
    "print('Training with {} WordNet words'.format(train_val_split_idx))\n",
    "\n",
    "MAX_NUM_INPUTS = max([len(i) for i in words[:train_val_split_idx]])\n",
    "EPOCH_SIZE = train_val_split_idx\n",
    "NUM_EPOCHS = 100\n",
    "BATCH_SIZE = np.array([len(i) for i in words[:train_val_split_idx]]).mean()\n",
    "print('Max word length: {}, average word length: {:0.1f}'.format(MAX_NUM_INPUTS, BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"player\"></a>\n",
    "## Create the game player\n",
    "\n",
    "This is a \"wrapper\" of sorts around our neural network model, that handles the dynamics of gameplay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HangmanPlayer:\n",
    "    def __init__(self, word, model, lives=10):\n",
    "        self.original_word = word\n",
    "        self.full_word = [ord(i)-97 for i in word]\n",
    "        self.letters_guessed = set([])\n",
    "        self.letters_remaining = set(self.full_word)\n",
    "        self.lives_left = lives\n",
    "        self.obscured_words_seen = []\n",
    "        self.letters_previously_guessed = []\n",
    "        self.guesses = []\n",
    "        self.correct_responses = []\n",
    "        self.z = model\n",
    "        return\n",
    "    \n",
    "    def encode_obscured_word(self):\n",
    "        word = [i if i in self.letters_guessed else 26 for i in self.full_word]\n",
    "        obscured_word = np.zeros((len(word), 27), dtype=np.float32)\n",
    "        for i, j in enumerate(word):\n",
    "            obscured_word[i, j] = 1\n",
    "        return(obscured_word)\n",
    "    \n",
    "    def encode_guess(self, guess):\n",
    "        encoded_guess = np.zeros(26, dtype=np.float32)\n",
    "        encoded_guess[guess] = 1\n",
    "        return(encoded_guess)\n",
    "\n",
    "    def encode_previous_guesses(self):\n",
    "        # Create a 1 x 26 vector where 1s indicate that the letter was previously guessed\n",
    "        guess = np.zeros(26, dtype=np.float32)\n",
    "        for i in self.letters_guessed:\n",
    "            guess[i] = 1\n",
    "        return(guess)\n",
    "    \n",
    "    def encode_correct_responses(self):\n",
    "        # To be used with cross_entropy_with_softmax, this vector must be normalized\n",
    "        response = np.zeros(26, dtype=np.float32)\n",
    "        for i in self.letters_remaining:\n",
    "            response[i] = 1.0\n",
    "        response /= response.sum()\n",
    "        return(response)\n",
    "    \n",
    "    def store_guess_and_result(self, guess):\n",
    "        # Record what the model saw as input: an obscured word and a list of previously-guessed letters\n",
    "        self.obscured_words_seen.append(self.encode_obscured_word())\n",
    "        self.letters_previously_guessed.append(self.encode_previous_guesses())\n",
    "        \n",
    "        # Record the letter that the model guessed, and add that guess to the list of previous guesses\n",
    "        self.guesses.append(guess)\n",
    "        self.letters_guessed.add(guess)\n",
    "        \n",
    "        # Store the \"correct responses\"\n",
    "        correct_responses = self.encode_correct_responses()\n",
    "        self.correct_responses.append(correct_responses)\n",
    "        \n",
    "        # Determine an appropriate reward, and reduce # of lives left if appropriate\n",
    "        if guess in self.letters_remaining:\n",
    "            self.letters_remaining.remove(guess)\n",
    "        \n",
    "        if self.correct_responses[-1][guess] < 0.00001:\n",
    "            self.lives_left -= 1\n",
    "        return\n",
    "                \n",
    "    def run(self):\n",
    "        # Play a game until we run out of lives or letters\n",
    "        while (self.lives_left > 0) and (len(self.letters_remaining) > 0):\n",
    "            guess = np.argmax(np.squeeze(self.z.eval({self.z.arguments[0]: np.array(self.encode_obscured_word()),\n",
    "                                                      self.z.arguments[1]: np.array(self.encode_previous_guesses())})))\n",
    "            self.store_guess_and_result(guess)\n",
    "        \n",
    "        # Return the observations for use in training (both inputs, predictions, and losses)\n",
    "        return(np.array(self.obscured_words_seen),\n",
    "               np.array(self.letters_previously_guessed),\n",
    "               np.array(self.correct_responses))\n",
    "    \n",
    "    def show_words_seen(self):\n",
    "        for word in self.obscured_words_seen:\n",
    "            print(''.join([chr(i + 97) if i != 26 else ' ' for i in word.argmax(axis=1)]))\n",
    "            \n",
    "    def show_guesses(self):\n",
    "        for guess in self.guesses:\n",
    "            print(chr(guess + 97))\n",
    "            \n",
    "    def play_by_play(self):\n",
    "        print('Hidden word was \"{}\"'.format(self.original_word))\n",
    "        for i in range(len(self.guesses)):\n",
    "            word_seen = ''.join([chr(i + 97) if i != 26 else ' ' for i in self.obscured_words_seen[i].argmax(axis=1)])\n",
    "            print('Guessed {} after seeing \"{}\"'.format(chr(self.guesses[i] + 97),\n",
    "                                                        word_seen))\n",
    "            \n",
    "    def evaluate_performance(self):\n",
    "        # Assumes that the run() method has already been called\n",
    "        ended_in_success = self.lives_left > 0\n",
    "        letters_in_word = set([i for i in self.original_word])\n",
    "        correct_guesses = len(letters_in_word) - len(self.letters_remaining)\n",
    "        incorrect_guesses = len(self.guesses) - correct_guesses\n",
    "        return(ended_in_success, correct_guesses, incorrect_guesses, letters_in_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"model\"></a>\n",
    "## Create the model\n",
    "\n",
    "The network will accept as input:\n",
    "- an n-letter obscured word, with letters/blanks encoded as one-hots (n x 27 dense vector)\n",
    "- a 1 x 26 vector of guesses made so far (1 if the letter has been guessed; 0 otherwise\n",
    "\n",
    "It will return as output:\n",
    "- a 1 x 26 vector of which argmax is the letter the model \"chooses next\"\n",
    "\n",
    "The variable-length obscured word is fed into an LSTM, and the final output of the LSTM is combined with info on the guesses so far before entering dense layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_LSTM_net(input_obscured_word_seen, input_letters_guessed_previously):\n",
    "    with cntk.layers.default_options(initial_state = 0.1):\n",
    "        lstm_outputs = cntk.layers.Recurrence(cntk.layers.LSTM(MAX_NUM_INPUTS))(input_obscured_word_seen)\n",
    "        final_lstm_output = cntk.ops.sequence.last(lstm_outputs)\n",
    "        combined_input = cntk.ops.splice(final_lstm_output, input_letters_guessed_previously)\n",
    "        dense_layer = cntk.layers.Dense(26, name='final_dense_layer')(combined_input)\n",
    "        return(dense_layer)\n",
    "    \n",
    "input_obscured_word_seen = cntk.ops.input_variable(shape=27,\n",
    "                                                   dynamic_axes=[cntk.Axis.default_batch_axis(),\n",
    "                                                                 cntk.Axis.default_dynamic_axis()],\n",
    "                                                   name='input_obscured_word_seen')\n",
    "input_letters_guessed_previously = cntk.ops.input_variable(shape=26,\n",
    "                                                           dynamic_axes=[cntk.Axis.default_batch_axis()],\n",
    "                                                           name='input_letters_guessed_previously')\n",
    "\n",
    "z = create_LSTM_net(input_obscured_word_seen, input_letters_guessed_previously)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"train\"></a>\n",
    "## Train the model\n",
    "\n",
    "Set some learning parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define loss and displayed metric\n",
    "input_correct_responses = cntk.ops.input_variable(shape=26,\n",
    "                                                  dynamic_axes=[cntk.Axis.default_batch_axis()],\n",
    "                                                  name='input_correct_responses')\n",
    "pe = cntk.losses.cross_entropy_with_softmax(z, input_correct_responses)\n",
    "ce = cntk.metrics.classification_error(z, input_correct_responses)\n",
    "\n",
    "learning_rate = 0.1\n",
    "lr_schedule = cntk.learners.learning_rate_schedule(learning_rate, cntk.UnitType.minibatch)\n",
    "momentum_time_constant = cntk.learners.momentum_as_time_constant_schedule(BATCH_SIZE / -np.log(0.9)) \n",
    "learner = cntk.learners.fsadagrad(z.parameters,\n",
    "                                  lr=lr_schedule,\n",
    "                                  momentum=momentum_time_constant,\n",
    "                                  unit_gain = True)\n",
    "trainer = cntk.Trainer(z, (pe, ce), learner)\n",
    "progress_printer = cntk.logging.progress_print.ProgressPrinter(freq=EPOCH_SIZE, tag='Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the actual training using the code cell below. Note that this step will take many hours to complete:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_samples = 0\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    i = 0\n",
    "    while total_samples < (epoch+1) * EPOCH_SIZE:\n",
    "        word = words[i]\n",
    "        i += 1\n",
    "        \n",
    "        other_player = HangmanPlayer(word, z)\n",
    "        words_seen, previous_letters, correct_responses = other_player.run()\n",
    "        \n",
    "        trainer.train_minibatch({input_obscured_word_seen: words_seen,\n",
    "                                 input_letters_guessed_previously: previous_letters,\n",
    "                                 input_correct_responses: correct_responses})\n",
    "        total_samples += 1\n",
    "        progress_printer.update_with_trainer(trainer, with_metric=True)\n",
    "        \n",
    "    progress_printer.epoch_summary(with_metric=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When interpreting the loss and metric during training, keep in mind:\n",
    "- The \"classification error\" is the $\\ell_1$ distance between the softmax of the model's output and a normalized vector indicating the true responses. For example, if the letters \"a\" and \"b\" were the only correct responses, the normalized vector would be [0.5, 0.5, 0, ... 0]. It is *not* the fraction of incorrect guesses and not easily interpreted in an absolute sense. (We will switch to human-interpretable metrics after training finishes; for now, look for improvements in performance.)\n",
    "- The loss function is the cross entropy between the softmax of the model's output and the normalized vector described above.\n",
    "\n",
    "Expect training to take several hours on an Azure NC6 GPU DSVM.\n",
    "\n",
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_filename = './hangman_model.dnn'\n",
    "z.save(model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a name=\"eval\"></a>\n",
    "## Evaluating results\n",
    "\n",
    "### Anecdotal version of performance evaluation\n",
    "Let's check out how the game went for the last word seen during training. (That game's results are still stored in the variable `other_player`.) Your word will of course vary due to random word shuffling during data partitioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden word was \"unquestionably\"\n",
      "Guessed n after seeing \"              \"\n",
      "Guessed r after seeing \" n       n    \"\n",
      "Guessed e after seeing \" n       n    \"\n",
      "Guessed i after seeing \" n  e    n    \"\n",
      "Guessed t after seeing \" n  e  i n    \"\n",
      "Guessed l after seeing \" n  e ti n    \"\n",
      "Guessed s after seeing \" n  e ti n  l \"\n",
      "Guessed y after seeing \" n  esti n  l \"\n",
      "Guessed u after seeing \" n  esti n  ly\"\n",
      "Guessed g after seeing \"un uesti n  ly\"\n",
      "Guessed o after seeing \"un uesti n  ly\"\n",
      "Guessed a after seeing \"un uestion  ly\"\n",
      "Guessed c after seeing \"un uestiona ly\"\n",
      "Guessed f after seeing \"un uestiona ly\"\n",
      "Guessed q after seeing \"un uestiona ly\"\n",
      "Guessed b after seeing \"unquestiona ly\"\n"
     ]
    }
   ],
   "source": [
    "other_player.play_by_play()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this specific case, the performance is encouraging!\n",
    "\n",
    "### More thorough version of performance evaluation\n",
    "\n",
    "Now we play hangman with all words in the validation set, and quantify performance with a few metrics:\n",
    "- fraction of games won\n",
    "- average number of correct guesses\n",
    "- average number of incorrect guesses\n",
    "\n",
    "Note that the number of incorrect guesses is bounded by the number of lives per game (set to \"10\" as of this writing), i.e. how many \"body parts\" one draws on the hangman.\n",
    "\n",
    "First we evaluate the model on all words in the validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(my_words, my_model):\n",
    "    results = []\n",
    "    for word in my_words:\n",
    "        my_player = HangmanPlayer(word, my_model)\n",
    "        _ = my_player.run()\n",
    "        results.append(my_player.evaluate_performance())\n",
    "    df = pd.DataFrame(results, columns=['won', 'num_correct', 'num_incorrect', 'letters'])\n",
    "    return(df)\n",
    "\n",
    "# Expect this to take roughly ten minutes\n",
    "result_df = evaluate_model(words[train_val_split_idx:], z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we summarize the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on the validation set:\n",
      "- Averaged 6.4 correct and 7.5 incorrect guesses per game\n",
      "- Won 62.0% of games played\n"
     ]
    }
   ],
   "source": [
    "print('Performance on the validation set:')\n",
    "print('- Averaged {:0.1f} correct and {:0.1f} incorrect guesses per game'.format(result_df['num_correct'].mean(),\n",
    "                                                                       result_df['num_incorrect'].mean()))\n",
    "print('- Won {:0.1f}% of games played'.format(100 * result_df['won'].sum() / len(result_df.index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"fun\"></a>\n",
    "## Just for fun -- play hangman with your favorite word\n",
    "\n",
    "In case you would like to see how the trained model performs on your favorite word!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden word was \"microsoft\"\n",
      "Guessed e after seeing \"         \"\n",
      "Guessed i after seeing \"         \"\n",
      "Guessed a after seeing \" i       \"\n",
      "Guessed n after seeing \" i       \"\n",
      "Guessed r after seeing \" i       \"\n",
      "Guessed u after seeing \" i r     \"\n",
      "Guessed o after seeing \" i r     \"\n",
      "Guessed t after seeing \" i ro o  \"\n",
      "Guessed g after seeing \" i ro o t\"\n",
      "Guessed f after seeing \" i ro o t\"\n",
      "Guessed m after seeing \" i ro oft\"\n",
      "Guessed c after seeing \"mi ro oft\"\n",
      "Guessed l after seeing \"micro oft\"\n",
      "Guessed s after seeing \"micro oft\"\n"
     ]
    }
   ],
   "source": [
    "model_filename = './hangman_model.dnn'\n",
    "z2 = cntk.load_model(model_filename)\n",
    "my_word = 'microsoft'\n",
    "\n",
    "my_player = HangmanPlayer(my_word, z2)\n",
    "_ = my_player.run()\n",
    "my_player.play_by_play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model won this game\n",
      "The model made 8 correct guesses and 6 incorrect guesses\n"
     ]
    }
   ],
   "source": [
    "results = my_player.evaluate_performance()\n",
    "print('The model {} this game'.format('won' if results[0] else 'did not win'))\n",
    "print('The model made {} correct guesses and {} incorrect guesses'.format(results[1], results[2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
