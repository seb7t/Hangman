{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-13T18:33:05.837393Z",
     "start_time": "2024-03-13T18:33:05.758592Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mstring\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mcollections\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m deque\n\u001B[0;32m----> 5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnn\u001B[39;00m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01moptim\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01moptim\u001B[39;00m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "from collections import deque\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class HangmanEnvironment:\n",
    "    def __init__(self, max_attempts=6):\n",
    "        self.word_list = self.build_dictionary('words_250000_train.txt')\n",
    "        self.max_attempts = max_attempts\n",
    "        self.reset()\n",
    " \n",
    "    def reset(self):\n",
    "        self.secret_word = random.choice(self.word_list).lower()\n",
    "        self.attempts_remaining = self.max_attempts\n",
    "        self.current_state = \"_\" * len(self.secret_word)\n",
    "        self.letters_guessed = set()\n",
    "        return self.get_observation()\n",
    "\n",
    "    def get_observation(self):\n",
    "        encoded_state = [1 if letter in self.letters_guessed else 0 for letter in string.ascii_lowercase]\n",
    "        return np.array(encoded_state + [ord(c) - ord('a') if c != '_' else 26 for c in self.current_state] + [self.attempts_remaining])\n",
    "    \n",
    "    def build_dictionary(self, dictionary_file_location):\n",
    "        text_file = open(dictionary_file_location,\"r\")\n",
    "        full_dictionary = text_file.read().splitlines()\n",
    "        text_file.close()\n",
    "        return full_dictionary\n",
    "\n",
    "    def step(self, action):\n",
    "        letter = string.ascii_lowercase[action]\n",
    "        if letter in self.letters_guessed:\n",
    "            return self.get_observation(), -1, False, {}\n",
    "        self.letters_guessed.add(letter)\n",
    "\n",
    "        if letter in self.secret_word:\n",
    "            new_state = \"\".join([c if c in self.letters_guessed else '_' for c in self.secret_word])\n",
    "            self.current_state = new_state\n",
    "            reward = 10 if new_state == self.secret_word else 1\n",
    "            done = new_state == self.secret_word\n",
    "        else:\n",
    "            self.attempts_remaining -= 1\n",
    "            reward = -1\n",
    "            done = self.attempts_remaining == 0\n",
    "\n",
    "        return self.get_observation(), reward, done, {}\n",
    "\n",
    "    def render(self):\n",
    "        print(f\"Word: {self.current_state} Attempts Left: {self.attempts_remaining}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "34319b905f01c3de"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class DQNNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(DQNNetwork, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, output_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self, state_dim, action_dim, learning_rate=1e-3):\n",
    "        self.state_dim = state_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.model = DQNNetwork(state_dim, action_dim)\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.memory = deque(maxlen=10000)\n",
    "        self.gamma = 0.99  # Discount factor\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state, epsilon=0.1):\n",
    "        if random.random() < epsilon:\n",
    "            return random.randrange(self.action_dim)\n",
    "        state = torch.FloatTensor(state).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            action_values = self.model(state)\n",
    "        return np.argmax(action_values.cpu().data.numpy())\n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        if len(self.memory) < batch_size:\n",
    "            return\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = reward\n",
    "            if not done:\n",
    "                next_state = torch.FloatTensor(next_state).unsqueeze(0)\n",
    "                target = (reward + self.gamma * torch.max(self.model(next_state).detach()))\n",
    "            state = torch.FloatTensor(state).unsqueeze(0)\n",
    "            target_f = self.model(state)\n",
    "            target_f[0][action] = target\n",
    "            self.optimizer.zero_grad()\n",
    "            loss = self.criterion(target_f, self.model(state))\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "    def train(self, env, episodes, batch_size):\n",
    "        for e in range(episodes):\n",
    "            state = env.reset()\n",
    "            state = np.reshape(state, [1, state_dim])\n",
    "            done = False\n",
    "            while not done:\n",
    "                action = self.act(state)\n",
    "                next_state, reward, done, _ = env.step(action)\n",
    "                next_state = np.reshape(next_state, [1, state_dim])\n",
    "                self.remember(state, action, reward, next_state, done)\n",
    "                state = next_state\n",
    "                if done:\n",
    "                    print(f\"Episode: {e+1}/{episodes}, score: {reward}\")\n",
    "            self.replay(batch_size)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eefa2e58dfcc0680"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "env = HangmanEnvironment()\n",
    "state_dim = env.get_observation().shape[0]\n",
    "action_dim = 26  # Number of letters in the English alphabet\n",
    "\n",
    "agent = DQNAgent(state_dim, action_dim)\n",
    "episodes = 1000\n",
    "batch_size = 32\n",
    "\n",
    "agent.train(env, episodes, batch_size)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5677e811766d2096"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
